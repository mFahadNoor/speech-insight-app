# Install required libraries for Google Colab
!pip install -q transformers datasets scikit-learn

# Import libraries
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from datasets import load_dataset
from sklearn.metrics import f1_score, accuracy_score
import numpy as np

# Load GoEmotions dataset
dataset = load_dataset("go_emotions")

# Define label count and model checkpoint
label_list = dataset["train"].features["labels"].feature.names
num_labels = len(label_list)
checkpoint = "distilbert-base-uncased"

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Preprocess function
def preprocess(example):
    return tokenizer(example["text"], truncation=True, padding="max_length", max_length=128)

# Apply tokenization
encoded_dataset = dataset.map(preprocess, batched=True)

# Set format for PyTorch
encoded_dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

# Define model
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, problem_type="multi_label_classification")

# Metric computation
def compute_metrics(pred):
    logits, labels = pred
    sigmoid = torch.nn.Sigmoid()
    probs = sigmoid(torch.tensor(logits))
    y_pred = np.where(probs > 0.5, 1, 0)
    y_true = labels
    f1 = f1_score(y_true, y_pred, average="micro")
    acc = accuracy_score(y_true, y_pred)
    return {"accuracy": acc, "f1": f1}

# Training arguments
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    logging_dir="./logs",
    load_best_model_at_end=True,
    metric_for_best_model="f1",
)

# Trainer setup
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=encoded_dataset["train"],
    eval_dataset=encoded_dataset["validation"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

# Train model
trainer.train()

# Save model
model.save_pretrained("emotion_model")
tokenizer.save_pretrained("emotion_model")

